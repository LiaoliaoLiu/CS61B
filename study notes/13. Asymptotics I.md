# Lecture
- [Now we moved our focus from saving your time to saving computer's time](https://youtu.be/DF1ThvyLwnk?list=PL8FaHk7qbOD4oAdQOZ765z6aeqyKs2593&t=31)
- [Big Theta vs. big O](https://youtu.be/vg9BDZwQtdQ?list=PL8FaHk7qbOD4oAdQOZ765z6aeqyKs2593&t=155)
  - Big O: order of growth is less than or equal to f(N). (upper bound)

# Overview
**Runtime Measurement.** Some natural techniques:
- Measure the number of seconds that a program takes to complete using a stopwatch (either physical or in software). This tells you the actual runtime, but is dependent on the machine and inputs.
- Count the number of operations needed for inputs of a given size. This is a machine independent analysis, but still depends on the input, and also doesn’t actually tell you how long the code takes to run.
- Derive an algebraic expression relating the number of operations to the size of an input. This tells you how the algorithm scales, but does not tell you how long the code takes to run.

**Algorithm Scaling.** While we ultimately care about the runtime of an algorithm in seconds, we’ll often say that one algorithm is better than another simply because of how it scales. *By scaling, we mean how the runtime of a piece of code grows as a function of its input size.* For example, inserting at the beginning of ArrayList on an old computer might take $R(N)=0.0001N$ seconds (take resize into consideration), where N is the size of the list.

For example, if the runtime of two algorithms is $R1(N)=N2$, and $R2(N)=5000+N$, we’d say algorithm 2 is better, even though R1 is much faster for small N.

A rough justification for this argument is that performance critical situations are exactly those for which N is “large”, though this is not an obvious fact. In almost all cases we’d prefer the linear algorithm. In some limited real-world situations like *matrix multiplication*, one might select one algorithm for small N, and another algorithm for large N. We won’t do this in 61B.

**Simplfying Algebraic Runtime.** We utilize four simplifications to make runtime analysis simpler.

- Pick the operation likely happens the most times to be our cost model, e.g. # of array accesses.
- Focus on the worst case, i.e. if the number of operations is between $1$ and $2N+1$, consider only the $2N+1$.
- Ignore small inputs, e.g. treat $2N+1$ just like $2N$.
- Ignore constant scaling factor, e.g. treat $2N$ just like $N$.

**Order of Growth.** The result of applying our last 3 simplifications gives us the order of growth of a function. So for example, suppose $R(N)=4N2+3N+6$, we’d say that the order of growth of $R(N)$ is $N2$.

**Simplified Analysis.** Use intuition and inspection to find the order of growth of the number of operations. One common intuitive/inspection-based approach is use [geometric intuition](https://youtu.be/lJ1A8Jyeba0?list=PL8FaHk7qbOD4oAdQOZ765z6aeqyKs2593&t=120).

**Big Theta.** See [CS61A Lecture 22 Efficiency](/CS/CS61A/Lecture%2022%20Efficiency.md###Theta-Notation).

# Exercise
Suppose we have a function bleepBlorp, and its runtime R(N) has order of growth Θ(N2). Which of the following can we say?
- $R(N)∈Θ(N2)$ true, this is what order of growth means!
- $R(N)∈Θ(N2)$ for any inputs true, this statement is exactly the same as the one above
- $R(N)∈Θ(N2)$ for worst case inputs true, since also true for ANY input
- For large N, if we run bleepBlorp on an input of size $N$, and an input of size $10N$, we will have to wait roughly 100 times as long for the larger input. true, this is the nature of quadratics
- If we run bleepBlorp on an input of size 1000, and an input of size 10000, we will have to wait roughly 100 times as long for the larger input. false, 1000 may not be a large enough N to exhibit quadratic behavior

# Efficient Programming

## Encapsulation, API's, ADT's
> “An engineer will do for a dime what any fool will do for a dollar” -- Paul Hilfinger

Efficiency comes in two flavors:

1.) Programming cost.
- How long does it take to develop your programs?
- How easy is it to read, modify, and maintain your code?

2.) Execution cost (starting next week).
- How much time does your program take to execute?
- How much memory does your program require?

Today, we will be focusing on how to reduce programming cost. Of course, want to keep programming costs low, both so we can write code faster and so we can have less frustrated people which will also help us write code faster (people don't code very fast when they are frustrated).

Some helpful Java features discussed in 61B:
- Packages.
  - Good: Organizing, making things package private
  - Bad: Specific
- Static type checking.
  - Good: Checks for errors early , reads more like a story
  - Bad: Not too flexible, (casting)
- Inheritance.
  - Good: Reuse of code
  - Bad: “Is a”, the path of debugging gets annoying, can’t instantiate, implement every method of an interface

We will explore some new ways in this chapter!

### Encapsulation
We will first define a few terms:
- **Module**: A set of methods that work together as a whole to perform some task or set of related tasks.
- **Encapsulated**: A module is said to be encapsulated if its implementation is completely hidden, and it can be accessed only through a documented interface.

### API's
An API(Application Programming Interface) of an ADT is the list of constructors and methods and a short description of each.

API consists of syntactic and semantic specification.
- Compiler verifies that **syntax** is met.
  - AKA, everything specified in the API is present.
- Tests help verify that **semantics** are correct.
  - AKA everything actually works the way it should.
  - Semantic specification usually written out in English (possibly including usage examples). Mathematically precise formal specifications are somewhat possible but not widespread.

### ADT's
ADT's (Abstract Data Structures) are high-level types that are defined by their **behaviors**, not their implementations.

i.e.) Deque in Proj1 was an ADT that had certain behaviors (addFirst, addLast, etc.). But, the data structures we actually used to implement it was ArrayDeque and LinkedListDeque

Some ADT's are actually special cases of other ADT's. For example, *Stacks and Queues are just lists that have even more specific behavior.*

#### Extention vs. Delegation
```java
public class ExtensionStack<Item> extends LinkedList<Item> {
    public void push(Item x) {
        add(x);
    }
}
```
This solution uses extension. it simply borrow the methods from LinkedList<Item> and uses them as its own.
```java
public class DelegationStack<Item> {
    private LinkedList<Item> L = new LinkedList<Item>();
    public void push(Item x) {
        L.add(x);
    }
}
```
This approach uses Delegation. It creates a Linked List object and calls its methods to accomplish its goal.
```java
public class StackAdapter<Item> {
    private List L;
    public StackAdapter(List<Item> worker) {
        L = worker;
    }

    public void push(Item x) {
        L.add(x);
    }
}
```
This approach is similar to the previous one, except it can use any class that implements the List interface (Linked List, ArrayList, etc).

Earlier in the section define that delegation is accomplished by passing in a class while extension is defined as inheriting (just because it may be hard to notice at first glance).

**Delegation vs Extension**: Right now it may seem that Delegation and Extension are pretty much interchangeable; however, there are some important differences that must be remembered when using them.

- Extension tends to be used when you know what is going on in the parent class. In other words, you know how the methods are implemented. 
- Additionally, with extension, you are basically saying that the class you are extending from acts similarly to the one that is doing the extending. 
- On the other hand, Delegation is when you do not want to consider your current class to be a version of the class that you are pulling the method from.

### Views
Views are an alternative representation of an existed object. Views essentially limit the access that the user has to the underlying object. However, changes done through the views will affect the actual object.
```java
/** Create an ArrayList. */
List<String> L = new ArrayList<>();
/** Add some items. */
L.add(“at”); L.add(“ax”); …
```
Say you only want a list from index 1 and 4. Then you can use a method called sublist do this by the following and you will
```java
/** subList me up fam. */
List<String> SL = l.subList(1, 4);
```
Now why is this useful? Well say we want to reverse only this part of the original list. For example in the below image, we would want to reverse `ax` `ban` `bat` in the above picture.

![views-example](https://joshhug.gitbooks.io/hug61b/content/assets/reverse_list1.png)

The most intuitive way is to create a method that takes in a list object and *the indices which should be reversed*. However, this can be a bit painful because we add some extraneous logic.

To get around doing this, we can just create a general reverse function that takes in a list and reverses that list. Because views mutates the underlying object that it represents, we can create a sublist like earlier and reverse the sublist. The end result would actually mutate the actual list and not the copy.

**How do you return an actual List but still have it affect another List?** is a bit confusing. Well the answer is access methods.
```java
List<Item> sublist(int start, int end){
    Return new this.Sublist(start,end);
}
```
This first thing to notice from the above code is that subList returns a List type. (`List<Item>`)
```java
Private class Sublist extends AbstractList<Item>{
    Private int start end;
    Sublist(inst start, int end){...}
}
```
Now the reason the sublist function returns a List is because the class SubList extends AbstractList. Since AbstractList implements the List interface both it and Sublist are List Types.

## The Takeaway:
- APIs are pretty hard to design; however, having a coherent design philosophy can make your code much cleaner and easier to deal with.
- Inheritance is tempting to use frequently, but it has problems and should be use sparingly, only when you are certain about attributes of your classes (both those being extended and doing the extending).

# Asymptotics I: An Introduction to Asymptotic Analysis
## Summary
- Given a piece of code, we can express its runtime as a function R(N)
  - N is some **property** of the input of the function
  - i.e. oftentimes, N represents the **size** of the input
- Rather than finding R(N) exactly, we instead usually only care about the **order of growth** of R(N).
- One approach (not universal):
  - Choose a representative operation
  - Let C(N) = count of how many times that operation occurs, as a function of N.
  - Determine order of growth $f(N)$ for $C(N)$, i.e. $C(N) \in \Theta(f(N))$
  - Often (but not always) we consider the worst case count.
  - If operation takes constant time, then $R(N) \in \Theta(f(N))$