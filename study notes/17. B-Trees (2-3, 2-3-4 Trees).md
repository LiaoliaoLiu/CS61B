# Lecture
- [The expected tree height proof for randomized trees came up in 2003](https://youtu.be/yz850zzjrHQ?list=PL8FaHk7qbOD41EHkD7CgQuRw1jpH_Fv7-&t=370)
  - The worst case runtime for contains operation is $\Theta (\log N)$ on a tree built with random inserts.
- [Random trees including deletion are still $\Theta (\log N)$](https://youtu.be/yz850zzjrHQ?list=PL8FaHk7qbOD41EHkD7CgQuRw1jpH_Fv7-&t=420)
- [Height of B-Tree is between $\log_{L+1} (N)$ and $\log_2 (N)$](https://youtu.be/Cg7k5wKGk_Q?list=PL8FaHk7qbOD41EHkD7CgQuRw1jpH_Fv7-&t=113)
  - L: Max number of itmes per nodes
- [Princeton class was far easier](https://youtu.be/0uiVyTt8A1E?t=1058)

# Overview
## BSTs
**Depth** We define the depth of a node as how far it is from the root. For consistency, we say the root has a depth of 0.

**Height** We define the height of a tree as the depth of the deepest node.

Notice that depending on how we insert into our BST, our height could vary drastically. We say a tree is “spindly” if it has height close to N and a tree is “bushy” if its height is closer to logN. For operations such as getting a node, we want to have the height to be as small as possible, thus favoring “bushy” BSTs

## B-Tress
Two specific B-Trees in this course are 2-3 Trees (A B-Tree where each node has 2 or 3 children), and 2-3-4/2-4 Trees (A B-Tree where each node has 2, 3, or 4 children). The key idea of a B-Tree is to over stuff the nodes at the bottom to prevent increaseing the height of the tree. This allows us to ensure a max height of logN.

Make sure you know how to insert into a B-Tree. Refer back to lecture slides for examples.

With our restriction on height, we get that the runtime for contains and add are both $\Theta (\log N)$

## B-Tree invariants
Because of how we add to our tree, we get two nice invariants for B-Trees:
1. All leaves must be the same distance from the source
2. A non-leaf node with k items mut has exactly k+1 children.

# Q&A
- [Why the total points keep increasing every semester](https://youtu.be/KH49oWy-WjI?t=151)
  - For fun.
  - It can make sure the autograder updated.
- [The inner most loop that should not be the cost model](https://youtu.be/KH49oWy-WjI?t=291)
  - > You should also notice the condition for loop
- [Randomness in the function itself](https://youtu.be/KH49oWy-WjI?t=1553)
  - > I believe the function itself has randomness inside should be inspected like amortized runtime quesions.
  - > You need to find the statics pattern.
- [Lecture 15 Level B Q4](https://youtu.be/KH49oWy-WjI?t=1553)
  - We can make sure the runtime is $O(N \log N)$, by two lines above.
  - It turns out it's $\Theta (N\log N)$. (has a $\Omega (N \log N)$ lower bound)
  - I don't find a nice way to proof this.
- [Difference between ADT and interface](https://youtu.be/KH49oWy-WjI?t=2208)
  - The idea of ADT was captured by interface in Java.
  - They are not the exact same thing because there are languages that don't have interface.
- [Proactive and reactive inplementation of B-trees](https://youtu.be/KH49oWy-WjI?t=2371)
  - I guess proactive is better, but reactive is easy to write and teach.
- [Why you choose left-middle number in B-Trees](https://youtu.be/KH49oWy-WjI?t=2596)
  - Arbitrary. You can also choose the left-most number, but the implementation would be harder.
- [Extremely high probability, almost guaranted for a random tree to be a $\log N$ height BST](https://youtu.be/KH49oWy-WjI?t=2713)

# Balanced Trees
## Intro to Balanced Search Trees
### BST Performance
Some terminology for BST performance:
- **depth**: the number of links between a node and the root.
- **height**: the lowest depth of a tree.
- **average depth**: average of the total depths in the tree. You calculate this by taking $\frac{\sum_{i=0}^D{d_in_i}}{N}$ where $d_i$ is depth and $n_i$ is number of nodes at that depth.

The **height** of the tree determines the worst-case runtime, because in the worst case the node we are looking for is at the bottom of the tree.

The **average depth** determines the average-case runtime.

### BST insertion order
You don't have to know the proof of this, but when we insert randomly into a BST the **average depth** and **height** are expected to be $\Theta(log N)$.

However, we won't always be able to insert into a BST in random order. What if our data comes in real-time? Then, we will be forced to insert in the order that data comes to us.

In the next chapter we will learn about a tree that always maintains its balance!

## B-Trees

Inventing logic:
1. The problem with BST's is that we always insert at a leaf node.
2. Let's just never add a leaf node! When we insert, let's just add to a current leaf node. This way, the height will never increase.
3. We still have to look through that node as if we are looking through an array in order to get to the 19 element.
4. Set a limit on the number of elements in a single node. When it already has 4 elements, we will split the node in half. by bumping up the middle left node.

### Insertion Process

The process of adding a node to a 2-3-4 tree is:

1. We still always inserting into a leaf node, so take the node you want to insert and traverse down the tree with it, going left and right according to whether or not the node to be inserted is greater than or smaller than the items in each node.
2. After adding the node to the leaf node, if the new node has 4 nodes, then pop up the middle left node and re-arrange the children accordingly.
3. If this results in the parent node having 4 nodes, then pop up the middle left node again, rearranging the children accordingly.
4. Repeat this process until the parent node can accommodate or you get to the root.

### B-Tree invariants

**Question:** Is the order matters when inserting into a B-Tree?

**Solution:** Consider inserting 1-7 into a B-tree. We can get a tree of height 1 by inserting in this order: 2, 3, 4, 5, 6, 1, 7. So yes, depending on the order you insert nodes the height of a B-tree may change. However, the tree will always be **bushy**.

A B-tree has the following helpful invariants:
- All leaves must be the same distance from the source.
- A non-leaf node with $k$ items must have exactly $k+1$ children.

In tandem, these invariants cause the tree to always be bushy.

### B-Tree runtime analysis

The worst-case runtime situation for search in a B-tree would be if each node had the maximum number of elements in it and we had to traverse all the way to the bottom. We will use $L$ to denote the number of elements in each node. This means would would need to explore $\log N$ nodes (since the max height is $\log N$ due to the bushiness invariant) and at each node we would need to explore $L$ elements. In total, we would need to run $L \log N$ operations. However, we know $L$ is a constant, so our total runtime is $O(\log N)$.

### [2-3 Tree Deletion](https://docs.google.com/presentation/d/1zhQDvbcDZ9RJgJl0bmqwFFlHP8ExbDFo36Q9ZWH9EgU/edit#slide=id.g508ece10b0_1_1305)

In a 2-3 Tree, when we delete α from a node with 2 or more children, we:
- Swap the value of the successor with α.
- Then we delete the successor value. (Successor will always be in a leaf node!)

If deleting from a leaf with multiple keys, the deletion is trivial. We simply remove the item from the leaf, and we are done.

If our leaf has a single key, we cannot simply remove the node entirely.
- Any node with k items must have k + 1 children!
- Instead, we’ll leave an empty node, which must be filled.
- Filling the empty node is complex and has many cases (coming soon).
  - FIEN Case 1A: Multi-Key Sibling
  - FIEN Case 2A: Multi-Key Parent
  - FIEN Case 3: Single-Key Parent and Sibling