# Lecture
- [radix tree/trie](https://youtu.be/Y6IXuadhiBE?list=PL8FaHk7qbOD7eyAcACitG8neRNL2rsvng&t=298)
- [Domain (key) Specific Sets and Maps](https://youtu.be/Y6IXuadhiBE?list=PL8FaHk7qbOD7eyAcACitG8neRNL2rsvng&t=447)
  - Suffix Trees
  - DAWG

# Overview
**Summary.** The sort problem is to take a sequence of objects and put them into the correct order. The search problem is to store a collection of objects such that they can be rapidly retrieved (i.e. how do we implement a Map or Set). We made the obersvation that BST maps are roughly analagous to comparison based sorting, and hash maps are roughly analagous to counting based (a.k.a. integer) sorting. We observed that we have a 3rd type of sort, which involves sorting by digit, which raised the question: What sort of data structure is analogous to LSD or MSD sort?

**Terminology.**
- Length of string key usually represented by L.
- Alphabet size usually represented by R.

**Tries.** Analogous to LSD sort. Know how to insert and search for an item in a Trie. Know that Trie nodes typically do not contain letters, and that instead letters are stored implicitly on edge links. Know that there are many ways of storing these links, and that the fastest but most memory hungry way is with an array of size R. We call such tries R-way tries.

**Advantages of Tries.** Tries have very fast lookup times, as we only ever look at as many characters as they are in the data weâ€™re trying to retrieve. However, their chief advantage is the ability to efficiently support various operations not supported by other map/set implementations including:
- longestPrefixOf
- prefixMatches
- spell checking

# Q&A
- [Will we talk about space complexity?](https://youtu.be/43Dy4thsUT4?t=1035)
  - Not very much. The reason is that the answers for the data structure we use are not very rich.
  - When we talk about sorting algorithms, we will talk about that.
- [a very spindly k-d tree requires a much more sophisticated approach, e.g. a k-d-b-tree.](https://youtu.be/43Dy4thsUT4?t=2122)
- [Josh's favorite OS](https://youtu.be/43Dy4thsUT4?t=2181)
  - Josh liked high refresh rate but last time he didn't feel right in Linux GUI.
  - Windows is more compatible with a bunch of tools.
  - WSL2 is nice.
  - Josh did like the philosophy of Linux.
- [There is a really interesting connection between BST and Quick Sort.](https://youtu.be/43Dy4thsUT4?t=2505)
- [Trie is the basic data structure used for auto-completing in search engine.](https://youtu.be/43Dy4thsUT4?t=2566)
- [Protocol Buffers is the basic data strcuture for Google's data retrieve](https://youtu.be/43Dy4thsUT4?t=2759)

# Data Structures Summary
## The Search Problem
The problem we are presented: Given a stream of data, retrieve information of interest.

All of the data structures we have discussed so far have been to solve the search problem. How you might ask? Each of the data structures we've learned are used for storing information in schemes that make searching efficient in specific scenarios.

## Search Data Structures

|     Name      |      Store Operation(s)      | Primary Retrieval Operation |       Retrieve By        |
| :-----------: | :--------------------------: | :-------------------------: | :----------------------: |
|     List      | add(key), insert(key, index) |         get(index)          |          index           |
|      Map      |       put(key, value)        |          get(key)           |       key identity       |
|      Set      |           add(key)           |      containsKey(key)       |       key identity       |
|      PQ       |           add(key)           |        getSmallest()        | key order (aka key size) |
| Disjoint Sets |     connect(int1, int2)      |   isConnected(int1, int2)   |    two integer values    |

Remember that these are **Abstract** Data Types. This means that we define the behavior, not the implementation. We've defined many of the possible implementations in previous chapters. Let's think about how these [implementations and ADTs interact](https://youtu.be/i-OuY5o_G8g?t=454).

## Abstraction
Abstraction often happens in layers. Abstract Data Types can often contain two abstract ideas boiling down to one implementation. Let's consider some examples:

- If we remembered the Priority Queue ADT, we were attempting to find an implementation that would be efficient for PQ operations. We decided that our Priority Queue would be implemented using a Heap Ordered Tree, but as we saw we had several approaches (1A, 1B, 1C, 2, 3) of representing a tree for heaps.
- A similar idea is an External Chaining Hash Table. This data structure is implemented using an array of buckets, but these buckets can be done using either an ArrayList, Resizing Array, Linked List, or BST.

These two examples tell us that we can often think of an ADT by the use of another ADT. And that Abstract Data Types have layers of abstraction, each defining a behavior that is more specific than the idea that came before it.

# Tries
We are now going to learn about a new data structure called Tries. These will serve as a new implementation (from what we have previously learned) of a Set and a Map that has some special functionality for certain types of data and information.

## Inventing the Trie
Tries are a very useful data structure used in cases where keys can be broken into "characters" and share prefixes with other keys (e.g. strings).

Suppose we had a set containing "sam", "sad", "sap", "same", "a", and "awls. How might we improve upon this using other possible data structures we know? How might we take advantage of the structure strings?

Here are some key ideas that we will use:
- Every node stores only one letter
- Nodes can be shared by multiple keys

Therefore, we can insert "sam", "sad", "sap", "same", "a", and "awls" into a tree structure that contains single character nodes. An important observation to make is that most of these words share the same *prefixes*, therefore we can utilize these similarly structured strings for our structure.

To search, we will traverse our trie and compare to each character of the string as we go down. Thus, there are only two cases when we wouldn't be able to find a string; either the final node is white or we fall off the tree.

- contains("sam"): true, blue node
- contains("sa"): false, white node
- contains("a"): true, blue node
- contains("saq"): false, fell off tree

## Summary
A key takeaway is that we can often improve a general-purpose data structure when we add specificity to our problem, often by adding additional constraints. For example, we improved our implementation of HashMap when we restricted the keys to only be ASCII character, creating extremely efficient data structure.

- There is a distinction between ADTs and specific implementations. As an example, Disjoint Sets is an ADT: any Disjoint Sets has the methods `connect(x, y)` and `isConnected(x, y)`. There are four different ways to implement those methods: Quick Find, Quick Union, Weighted QU, and WQUPC.
- The Trie is a specific implementation for Sets and Maps that is specialized for strings.
  - We give each node a single character and each node can be a part of several keys inside of the trie.
  - Searching will only fail if we hit an unmarked node or we fall off the tree
  - Short for Re**trie**val tree, almost everyone pronounces it as "try" but Edward Fredkin suggested it be pronounced as "tree"

## Implementation
- We'll take a first approach with the idea that each node stores a letter, its children, and a color.
- But we can make an important observation: each link corresponds to a character if and only if that character **exists**.
  - Therefore, we can remove the Node's character variable and instead base the value of the character from its position in the parent `DataIndexedCharMap`.

## Performance
Let's look at the runtime through a measurement that can be measured; in terms of L, the length of the key:
- `add`: $\Theta(L)$
- `contains`: $O(L)$

We have achieved constant runtime without having to worry about amortized resizing times or an even spreading of keys, but as we mentioned above our current design is extremely wasteful since each node contains an array for every single character even if that character doesn't exist.

## Child Tracking
The problem with this approach was that we would have initialized many **null** spots that don't contain any children.

- Alternate Idea #1: Hash-Table based Trie. This won't create an array of 128 spots, but instead initialize the default value and resize the array only when necessary with the load factor.
- Alternate Idea #2: BST based Trie. Again this will only create children pointers when necessary, and we will store the children in the BST. Obviously, we still have the worry of the runtime for searching in this BST, but this is not a bad approach.

When we implement a Trie, we have to pick a map to our children. A Map is an ADT, so we must also choose the underlying implementation for the map. What does this reiterate to us? There is an **abstraction** barrier between the implementations and the ADT that we are trying to create. This abstraction barrier allows us to take advantage of what each implementation has to offer when we try to meet the ADT behavior. Let's consider each advantage:

- DataIndexedCharMap
  - Space: 128 links per node
  - Runtime: $\Theta(1)$
- BST
  - Space: C links per node, where C is the number of children
  - Runtime: $O(\log R)$, where R is the size of the alphabet
- Hash Table
  - Space: C links per node, where C is the number of children
  - Runtime: $O(R)$, where R is the size of the alphabet

Note: Cost per link is higher in BST and Hash Tables; R is a fixed number (this means we can think of the runtimes as constant)

We can takeaway a couple of things. There is a slight memory and efficiency trade off (with BST/Hash Tables vs. DataIndexedCharMap). The runtimes for Trie operations are still constant without any caveats. Tries will especially thrive with some special operations.

## Trie String Operations
We can see that Tries offer us constant time lookup and insertion, but do they actually perform better than BSTs or Hash Tables? Possibly not. For every string we have to traverse through every character, whereas in BSTs we have access to the entire string immediately. So what are Tries good for then?

### Prefix Matching
Let's attempt to define a method collect which returns all of the keys in a Trie. The pseudocode will be as follows:
```
collect():
    Create an empty list of results x
    For character c in root.next.keys():
        Call colHelp(c, x, root.next.get(c))
    Return x

colHelp(String s, List<String> x, Node n):
    if n.isKey:
        x.add(s)
    For character c in n.next.keys():
        Call colHelp(s + c, x, n.next.get(c))
```
Now we can try writing the method keysWithPrefix which returns all keys that contain the prefix passed in as an argument. We will borrow heavily from the collect method above.
```
keysWithPrefix(String s):
    Find the end of the prefix, alpha
    Create an empty list x
    For c in alpha.next.keys():
        Call colHelp("sa" + c, x, alpha.next.get(c))
    Return x
```

## Autocomplete
One way to achieve this is using a Trie! We will build a map from strings to values.

- Values will represent how important Google thinks that string is (Probably frequency)
- Store billions of strings efficiently since they share nodes, less wasteful duplicates
- When a user types a query, we can call the method `keysWithPrefix(x)` and return the 10 strings with the highest value

One major flaw with this system is if the user types in short length strings. You can imagine that the number of keys with the prefix of the input is in the millions when in reality we only want 10. A possible solution to this issue is to store the best value of a substring in each node. We can then consider children in the order of the best value.

Another optimization is to merge nodes that are redundant. This would give us a "radix trie", which holds characters as well as strings in each node. We won't discuss this in depth.

## Summary
Knowing the types of data that you are storing can give you great power in creating efficient data structures. Specifically for implementing Maps and Sets, if we know that all keys will be Strings, we can use a Trie:

- Tries theoretically have better performances for searching and insertion than hash tables or balanced search trees
- There are more implementations for how to store the children of every node of the trie, specifically three. These three are all fine, but hash table is the most natural
    - `DataIndexedCharMap` (Con: excessive use of space, Pro: speed efficient)
    - `Bushy BST` (Con: slower child search, Pro: space efficient)
    - `Hash Table` (Con: higher cost per link, Pro: space efficient)
- Tries may not actually be faster in practice, but they support special string operations that other implementations don't
  - `longestPrefixOf` and `keysWithPrefix` are easily implemented since the trie is stored character by character
  - `keysWithPrefix` allows for algorithms like autocomplete to exist, which can be optimized through use of a priority queue.


|                       |  key type  |        get(x)         |          add(x)          |
| :-------------------: | :--------: | :-------------------: | :----------------------: |
|     Balanced BST      | comparable |   $\Theta(\log N)$    |     $\Theta(\log N)$     |
|    RSC Hash Table     |  hashable  | $\Theta(1)^{\dagger}$ | $\Theta(1)^{*{\dagger}}$ |
|  Data Indexed Array   |   chars    |      $\Theta(1)$      |       $\Theta(1)$        |
| Tries (BST, HT, DICM) |  Strings   |      $\Theta(1)$      |       $\Theta(1)$        |

*: Indicates "on average"; $\dagger$: Indicates items are evenly spread.