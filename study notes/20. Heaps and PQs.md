# Lecture
- [Heaps in data structure are completely unrelated to heaps in Computer Architecture](https://youtu.be/4WHrtiKTkA4?list=PL8FaHk7qbOD50LnOXTSpYgnVJQTIVFsmI&t=20)
- ['Seperate' and 'definately'](https://youtu.be/i-OuY5o_G8g?list=PL8FaHk7qbOD50LnOXTSpYgnVJQTIVFsmI&t=255)
  - separate, definitely.
- [Data structure summary](https://youtu.be/i-OuY5o_G8g?list=PL8FaHk7qbOD50LnOXTSpYgnVJQTIVFsmI&t=436)

# Overview
**Priority Queue.** A Max Priority Queue (or PQ for short) is an ADT that supports at least the insert and delete-max operations. A MinPQ supposert insert and delete-min.

**Heaps.** A max (min) heap is an array representation of a binary tree such that every node is larger (smaller) than all of its children. This definition naturally applies recursively, i.e. a heap of height 5 is composed of two heaps of height 4 plus a parent.

**Tree Representations.** Know that there are many ways to represent a tree, and that we use Approach 3b (see lecture slides) for representing heaps, since we know they are complete.

**Running times of various PQ implementations.** Know the running time of the three primary PQ operations for an unordered array, ordered array, and heap implementation.

# Heaps and Priority Queues
## PQ Interface
### The Priority Queue Interface
The last **ADT** we learned about were Binary Search Trees, which allowed us efficient search only taking $\log N$ time. This was because we could eliminate half of the elements at every step of our search. What if we cared more about quickly finding the *smallest* or *largest* element instead of quickly searching?

Now we come to the Abstract Data Type of a *Priority Queue*. The one caveat is that you can **only interact with the smallest item**s of this bag.
```java
/** (Min) Priority Queue: Allowing tracking and removal of 
  * the smallest item in a priority queue. */
public interface MinPQ<Item> {
    /** Adds the item to the priority queue. */
    public void add(Item x);
    /** Returns the smallest item in the priority queue. */
    public Item getSmallest();
    /** Removes the smallest item from the priority queue. */
    public Item removeSmallest();
    /** Returns the size of the priority queue. */
    public int size();
}
```

### Priority Queue Implementation
The **worst case runtimes** of our desired operations:
- Ordered Array
  - `add`: $\Theta (N)$ (Resizing, insertion with binary search takes $\Theta (\log N)$)
  - `getSmallest`: $\Theta (1)$
  - `removeSmallest`: $\Theta (N)$ (Resizing, $O(1)$ if not)
- Bushy BST
  - `add`: $\Theta (\log N)$
  - `getSmallest`: $\Theta (\log N)$
  - `removeSmallest`: $\Theta (\log N)$
- HashTable
  - `add`: $\Theta (1)$
  - `getSmallest`: $\Theta (N)$
  - `removeSmallest`: $\Theta (N)$

### Summary
- Priority Queue is an Abstract Data Type that optimizes for handling minimum or maximum elements.
- There can be space/memory benefits to using this specialized data structure.
- Implementations for ADTs that we currently know don't give us efficient runtimes for PQ operations.
  - A binary search tree among the other structures is the most efficient. But handling duplicate elements needs modification.

## Heap
### Heap Structure
We will define our binary min-heap as being **complete** and obeying **min-heap** property:
  - Min-heap: Every node is less than or equal to both of its children
  - Complete: Missing items only at the bottom level (if any), all nodes are as far left as possible.

![heap0](https://joshhug.gitbooks.io/hug61b/content/assets/heap-13.2.1.png)

### Heap Operations
The three methods we care about for the PriorityQueue ADT are `add`, `getSmallest`, and `removeSmallest`. We will start by conceptually describing how these methods can be implemented given our given schema of a heap.

- `add`: Add to the end of heap temporarily. Swim up the hierarchy to the proper place.
   - Swimming involves swapping nodes if child < parent
- `getSmallest`: Return the root of the heap (This is guaranteed to be the minimum by our *min-heap* property
- `removeSmallest`: Swap the last item in the heap into the root. Sink down the hierarchy to the proper place.
  - Sinking involves swapping nodes if parent > child. Swap with the smallest child to preserve *min-heap* property.

### Tree Representation
#### Approach 1a, 1b, and 1c
- **Tree1A**: children pointers
```java
public class Tree1A<Key> {
  Key k;
  Tree1A left;
  Tree1A middle;
  Tree1A right;
  ...
}
```
- **Tree1B**: children list
```java
public class Tree1B<Key> {
  Key k;
  Tree1B[] children;
  ...
}
```
- **Tree1C**: child-sibling linked lists
```java
public class Tree1C<Key> {
  Key k;
  Tree1C favoredChild;
  Tree1C sibling;
  ...
}
```

These explicit references take the form of pointers to the actual Tree objects that are our children. Let's think of more exotic approaches that don't store explicit references to children.

#### Approach 2
Recall the Disjoint Sets ADT. The way that we represented this Weighted Quick Union structure was through arrays. For representing a tree, we can store the *keys* array as well as a *parents* array. The keys array represent which index maps to which key, and the parents array represents which key is a child of another key (by index).
```java
public class Tree2<Key> {
  Key[] keys;
  int[] parents;
  ...
}
```
we can see:
- The tree is **complete**. This is a property we have defined earlier.
- The parents array has a sort of redundant pattern where elements are just doubled.
- Reading the level-order of the tree, we see that it matches exactly the order of the keys in the keys array.

#### Approach 3
We know the parents array is redundant so we can ignore it and we know that a tree can be represented by level order in an array (complete). Thus, we will take this complex 2D structure of the tree and flatten it into an array.
```java
public class TreeC<Key> {
  Key[] keys;
  ...
}
```
Given this implementation, we define the following code for the "swim" described in the Heap Operations section.
```java
public void swim(int k) {
    if (keys[parent(k)] > keys[k]) {
       swap(k, parent(k));
       swim(parent(k));              
    }
}
```

## Implementation Consideration
### The Implementation
In the actual implementation, we will leave one empty spot at the beginning of the array to simplify computation.
- `leftChild(k)`= $k * 2$
- `rightChild(k)`= $k * 2 + 1$
- `parent(k)` = $k / 2$

### Comparing to alternative implementations
|     Methods      | Ordered Array |    Bushy BST     | Hash Table  |       Heap       |
| :--------------: | :-----------: | :--------------: | :---------: | :--------------: |
|      `add`       |  $\Theta(N)$  | $\Theta(\log N)$ | $\Theta(1)$ | $\Theta(\log N)$ |
|  `getSmallest`   |  $\Theta(1)$  | $\Theta(\log N)$ | $\Theta(N)$ |   $\Theta(1)$    |
| `removeSmallest` |  $\Theta(N)$  | $\Theta(\log N)$ | $\Theta(N)$ | $\Theta(\log N)$ |

Couple notes:

- Heap operations are **amortized** analysis, since the array will have to resize (not a big deal)
- BST's can have constant time `getSmallest` if pointer is stored to smallest element
- Array-based heaps take around 1/3rd the memory it takes to represent a heap using approach 1A (direct pointers to children)