# Lecture
- [Meta goals](https://www.youtube.com/watch?v=JNa8BRRs8L4&list=PL8FaHk7qbOD59HbdZE3x52KOhJJS54BlT&index=1)
- [Why ListOfSetsDS is **complicated** and slow](https://youtu.be/W6Dckcv8PIo?list=PL8FaHk7qbOD59HbdZE3x52KOhJJS54BlT&t=72)
  - Requires iteraring through all the sets to find anything.
- [The choice of building blocks for high level DS will deeply affect the code's complexity and performance](https://youtu.be/W6Dckcv8PIo?list=PL8FaHk7qbOD59HbdZE3x52KOhJJS54BlT&t=223)
- [The connect operation of HightedQuickUnion is much more complex](https://youtu.be/xc9s9wdaSdU?list=PL8FaHk7qbOD59HbdZE3x52KOhJJS54BlT&t=278)
- [The hight of HightedQuickUnion is also $\Theta(log N)$](https://youtu.be/xc9s9wdaSdU?list=PL8FaHk7qbOD59HbdZE3x52KOhJJS54BlT&t=404)
- [Why Weight Istead of Height?](https://youtu.be/xc9s9wdaSdU?list=PL8FaHk7qbOD59HbdZE3x52KOhJJS54BlT&t=481)
  - You get no asymptotic performance gain with more complex code.
- [Path Compression: close to amortized (average) constant time](https://youtu.be/DZKzDebT4gU?list=PL8FaHk7qbOD59HbdZE3x52KOhJJS54BlT&t=321)

# Overview
**Algorthm Development.** Developing a good algorithm is an iterative process. We create a model of the problem, develop an algorithm, and revise the performance of the algorithm until it meets our needs. This lecture serves as an example of this process.

**The Dynamic Connectivity Problem.** The ultimate goal of this lecture was to develop a data type that support the following operations on a fixed number N of objects:
- `connect(int p, int q)` (called union in our optional textbook)
- `isConnected(int p, int q)` (called connected in our optional textbook)

We do not care about finding the actual path between p and q. We care only about their connectedness. A third operation we can support is very closely related to connected():

- `find(int p)`: The `find()` method is defined so that `find(p) == find(q)` iff `connected(p, q)`. We did not use this in class, but it’s in our textbook.

**Key observation: Connectedness is an equivalence relation.** Saying that two objects are connected is the same as saying they are in an equivalence class. This is just fancy math talk for saying “every object is in exactly one bucket, and we want to know if two objects are in the same bucket”. When you connect two objects, you’re basically just pouring everything from one bucket into another.

**Quick find.** This is the most natural solution, where each object is given an explicit number. Uses an array `id[]` of length N, where `id[i]` is the bucket number of object i (which is returned by `find(i)`). To connect two objects `p` and `q`, we set every object in `p`’s bucket to have `q`’s number.
- `connect`: May require many changes to id. Takes Θ(N) time, as algorithm must iterate over the entire array.
- `isConnected` (and `find`): take constant time.

**Quick union.** An alternate approach is to change the meaning of our id array. In this strategy, `id[i]` is the parent object of object i. An object can be its own parent. The `find()` method climbs the ladder of parents until it reaches the root (an object whose parent is itself). To connect `p` and `q`, we set the root of `p` to point to the root of `q`.
- `connect`: Requires only one change to `id[]`, but also requires root finding (worst case Θ(N) time).
- `isConnected` (and `find`): Requires root finding (worst case $Θ(N)$ time).

**Weighted quick union.** Rather than `connect(p, q)` making the root of `p` point to the root of `q`, we instead make the root of the smaller tree point to the root of the larger one. The tree’s size is the number of nodes, not the height of the tree. Results in tree heights of $lgN$.
- `connect`: Requires only one change to id, but also requires root finding (worst case $lgN$ time).
- `isConnected` (and find): Requires root finding (worst case $lgN$ time).

Warning: if the two trees have the same size, the book code has the opposite convention as quick union and sets the root of the second tree to point to the root of the first tree. This isn’t terribly important.

**Weighted quick union with path compression.** When find is called, every node along the way is made to point at the root. Results in nearly flat trees. Making $M$ calls to union and find with $N$ objects results in no more than $O(Mlog^∗N)$ array accesses, not counting the creation of the arrays. For any reasonable values of N in this universe that we inhabit, $log^∗(N)$ is at most 5. It is possible to derive an even tighter bound, mentioned briefly in class (known as the [Ackerman function](https://en.wikipedia.org/wiki/Ackermann_function)).

|      Implementation       | Constructor | connect  | isConnected |
| :-----------------------: | :---------: | :------: | :---------: |
|       ListOfSetsDS        |    Θ(N)     |   O(N)   |    O(N)     |
|        QuickFindDS        |    Θ(N)     |   Θ(N)   |    Θ(1)     |
|       QuickUnionDS        |    Θ(N)     |   O(N)   |    O(N)     |
|   WeightedQuickUnionDS    |    Θ(N)     | O(log N) |  O(log N)   |
| WQU with Path Compression |    Θ(N)     | O(α(N))* |  O(α(N))*   |


# Example Implementation
[QuickFind](http://algs4.cs.princeton.edu/15uf/QuickFindUF.java.html)

[QuickUnion](http://algs4.cs.princeton.edu/15uf/QuickUnionUF.java.html)

[WeightedQuickUnion](http://algs4.cs.princeton.edu/15uf/WeightedQuickUnionUF.java.html)

[Weighted Quick Union with Path Compression](http://algs4.cs.princeton.edu/15uf/QuickUnionPathCompressionUF.java.html)

# Q&A
- [If the best case is N=1 in a N times for loop, can we say the best case is $Theta(1)$?](https://youtu.be/Vkz2BDbcAKM?t=1131)
  - No!
  - We don't think of a small N as a "good case".
  - The whole point of asymptotics is we want to understand the large N behavior.
  - You let the N be 1 doesn't mean the program won't take N related times of opeartions.
  - Sometimes we use Big O notation is because in the best case, the number of operations becomes inrelavent to N.
- [Two philosophies: closely related to class or create something new](https://youtu.be/Vkz2BDbcAKM?t=1315)
- [Use pointer to improve Quick Find](https://youtu.be/Vkz2BDbcAKM?t=2325)
  - There will be redundent objects for the same set id.
  - It will also becomes a O(N) solution. (Imagine you want to union a lot different pairs, the total numer is N, you need to change N/2 - 1 objects' set IDs)
  - If you changes the object to be a pointer to another set id object, that will lead you to the quick union.
- [Optimazing data structure is heavily rely on throw away information we don't need](https://youtu.be/Vkz2BDbcAKM?t=2689)
- [Quick sort is a algorithm that has bad worst case performance but very good practical performance](https://youtu.be/Vkz2BDbcAKM?t=2828)

# Disjoint Sets
## Introduction
As a reminder, an **interface** determines what *behaviors* a data structure should have (but not how to accomplish it).

In addition to learning about how to implement a fascinating data structure, this chapter will be a chance to see how an implementation of a data structure evolves. We will discuss four iterations of a Disjoint Sets design before being satisfied: *Quick Find* → *Quick Union* → *Weighted Quick Union (WQU)* → *WQU with Path Compression*. **We will see how design decisions greatly affect asymptotic runtime and code complexity.**

## ListOfSets
Intuitively, we might first consider representing Disjoint Sets as a list of sets, e.g, `List<Set<Integer>>`.

For instance, if we have N=6 elements and nothing has been connected yet, our list of sets looks like: `[{0}, {1}, {2}, {3}, {4}, {5}, {6}]`. Looks good. However, consider how to complete an operation like `connect(5, 6)`. We'd have to iterate through up to N sets to find 5 and N sets to find 6. Our runtime becomes $O(N)$. And, if you were to try and implement this, the code would be quite complex.

> The lesson to take away is that initial design decisions determine our code complexity and runtime.

## Quick Find
Let's consider another approach using a single array of integers.
- The indices of the array represent the elements of our set.
- The value at an index is the set number it belongs to.

For example, we represent `{0, 1, 2, 4}, {3, 5}, {6}` as:

![quickfind0](https://joshhug.gitbooks.io/hug61b/content/chap9/9.2.1.png)

The array indices (0...6) are the elements. The value at `id[i]` is the set it belongs to. 

- *The specific set number doesn't matter as long as all elements in the same set share the same id.*
- You cannot make `id[i]` as a pointer to a SetID to improve its performance. See [Q&A](#qa).
- We call this implementation "Quick Find" because finding if elements are connected takes constant time.

```java
    /* need to iterate through the array => Θ(N) */
    public void connect(int p, int q){
        int pid = id[p];
        int qid = id[q];
        for (int i = 0; i < id.length; i++){
            if (id[i] == pid){
                id[i] = qid;
            }
        }
    }

    /* Θ(1) */
    public boolean isConnected(int p, int q){
        return (id[p] == id[q]);
    }
```

## Quick Union
Suppose we prioritize making the `connect` operation fast. We will still represent our sets with an array. Instead of an id, we assign each item the index of its parent. If an item has no parent, then it is a 'root' and we assign it a negative value.

![quickunion0](https://joshhug.gitbooks.io/hug61b/content/chap9/9.3.1.png)

For QuickUnion we define a helper function `find(int item)` which returns the root of the tree item is in. For example, for the sets above, `find(4) == 0`, `find(1) == 0`, `find(5) == 3`, etc. Each element has a unique root.

- To connect two items, we find the set that each item belongs to (the roots of their respective trees), and make one the child of the other.
  - In the best case, if `x` and `y` are both roots of their trees, then `connect(x, y)` just makes `x` point to `y`, a $\Theta(1)$ operation! (Hence the name QuickUnion)
- For `isConnected(x, y)` we simply check if find(x) == find(y).
- **In the worst case**, the tree appears to be a linked list. We have to traverse all the items to get to the root, which is a $\Theta(N)$ runtime.
- From the runtime chart, QuickUnion seems worse than QuickFind! Note however that $O(N)$ as an **upper bound**.

```java
public class QuickUnionDS implements DisjointSets {
    private int[] parent;

    public QuickUnionDS(int num) {
        parent = new int[num];
        for (int i = 0; i < num; i++) {
            parent[i] = i;
        }
    }

    private int find(int p) {
        while (parent[p] >= 0) {
            p = parent[p];
        }
        return p;
    }

    @Override
    public void connect(int p, int q) {
        int i = find(p);
        int j= find(q);
        parent[i] = j;
    }

    @Override
    public boolean isConnected(int p, int q) {
        return find(p) == find(q);
    }
}
```

## Weighterd Quick Union (WQU)
- **New rule:** whenever we call connect, we always link the root of the **smaller tree to the larger tree**.
- We determine smaller / larger by the number of items in a tree.
- Following this rule will give your trees a maximum height of $\log N$, where N is the number of elements in our Disjoint Sets.
- By extension, the runtimes of `connect` and `isConnected` are bounded by $O(\log N)$.

**Why logN?**

- Imagine any element $x$ in tree $T1$. 
- The depth of $x$ increases by $1$ only when $T1$ is placed below another tree $T2$. 
- When that happens, the size of the resulting tree will be at least double the size of $T1$ because $size(T2) \ge size(T1)$. 
- The tree with $x$ can double at most $\log_2 N$ times until we've reached a total of N items ($2^{\log_2 N} = N$). 
- So we can double up to $\log_2 N$ times and each time, our tree adds a level $\rightarrow$ maximum $\log_2 N$ levels.

## Weighted Quick Union with Path Compression
- The clever insight is realizing that whenever we call `find(x)` we have to traverse the path from x to root.
- So, along the way we can connect all the items we visit to their root at no extra asymptotic cost.
- Recall that **both** `connect(x, y)` and `isConnected(x, y)` always call `find(x)` and `find(y)`. Thus, after calling `connect` or `isConnected` enough, essentially all elements will point directly to their root.
- By extension, the average runtime of `connect` and `isConnected` becomes almost constant in the long term! This is called the *amortized runtime*.
- Path compression is actually even better than iterated log ($lg^*$) - it's bounded by the inverse [Ackermann function α](https://www.uni-trier.de/fileadmin/fb4/prof/INF/DEA/Uebungen_LVA-Ankuendigungen/ws07/KAuD/effi.pdf)