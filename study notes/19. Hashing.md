# Lecture
- [Hash Codes and the Pigeonhole Principle](https://youtu.be/ix2frc8dHbw?list=PL8FaHk7qbOD67rFIKNVkDcucFwNjUq9-d&t=127)
- [Hash Table is the most popular way to implemente a set or map](https://youtu.be/dF2DL98S5PY?list=PL8FaHk7qbOD67rFIKNVkDcucFwNjUq9-d&t=5)
- [Natural % (-1 % 4 = 3) in Java is `Math.floorMod`](https://youtu.be/dF2DL98S5PY?list=PL8FaHk7qbOD67rFIKNVkDcucFwNjUq9-d&t=207)
  - `-1 % 4 == -1`
  - `Math.floorMod` is for other purpose. It happened to have the function we want.
  - $-1 = 4(-1) + 3$
  - The default % requires `(a / b) * b + a % b == a`.
  - `(-1 / 4) * 4 == 0 * 4 == 0`, thus `-1 % 4 == -1`.
- [Good HashCode philosophy](https://youtu.be/14f8LxYREFQ?list=PL8FaHk7qbOD67rFIKNVkDcucFwNjUq9-d&t=75)
  - Java 8 hash code for strings represents strings as base 31 number.
  - Real hash codes don't care about uniqueness.
  - Stores calculated has code so future `hashCode` calls are faster.
- [In Base 126, any string that ends in the same last 32 characters has the same hash code](https://youtu.be/14f8LxYREFQ?list=PL8FaHk7qbOD67rFIKNVkDcucFwNjUq9-d&t=243)
  - Because of overflow.
- [A typical hash code base is a small prime](https://www.youtube.com/watch?v=14f8LxYREFQ&list=PL8FaHk7qbOD67rFIKNVkDcucFwNjUq9-d&index=8)
  - Using a prime base yields better "randomness" (back reference to Good HashCode philosophy)
- [Examples on hashing a collection and recursive data sturectures](https://youtu.be/14f8LxYREFQ?list=PL8FaHk7qbOD67rFIKNVkDcucFwNjUq9-d&t=360)

# Overview
**Brute force approach.** All data is just a sequence of bits. Can treat key as a gigantic number and use it as an array index. Requires exponentially large amounts of memory.

**Hashing.** Instead of using the entire key, represent entire key by a smaller value. In Java, we hash objects with a hashCode() method that returns an integer (32 bit) representation of the object.

**hashCode() to index conversion.** To use hashCode() results as an index, we must convert the `hashCode()` to a valid index. Modulus does not work since hashCode may be negative. Taking the absolute value then the modulus also doesn’t work since `Math.abs(Integer.MIN_VALUE)` is negative. Typical approach: use hashCode & 0x7FFFFFFF instead before taking the modulus.

**Hash function.** Converts a key to a value between 0 and M-1. In Java, this means calling `hashCode()`, setting the sign bit to 0, then taking the modulus.

**Designing good hash functions.** Requires a blending of sophisticated mathematics and clever engineering; beyond the scope of this course. Most important guideline is to use all the bits in the key. If `hashCode()` is known and easy to invert, adversary can design a sequence of inputs that result in everything being placed in one bin. Or if `hashCode()` is just plain bad, same thing can happen.

**Uniform hashing assumption.** For our analyses below, we assumed that our hash function distributes all input data evenly across bins. This is a strong assumption and never exactly satisfied in practice.

**Collision resolution.** Two philosophies for resolving collisions discussed in class: Separate (a.k.a. external) chaining and ‘open addressing’.

**Separate-chaining hash table.** Key-value pairs are stored in a linked list of nodes of length M. Hash function tells us which of these linked lists to use. Get and insert both require potentially scanning through entire list.

**Resizing separate chaining hash tables.** Understand how resizing may lead to objects moving from one linked list to another. Primary goal is so that M is always proportional to N, i.e. maintaining a load factor bounded above by some constant.

**Performance of separate-chaining hash tables.** Cost of a given get, insert, or delete is given by number of entries in the linked list that must be examined.
  - The expected amortized search and insert time (assuming items are distributed evenly) is N / M, which is no larger than some constant (due to resizing).

**Linear-probing hash tables.** We didn’t go over this in detail in 61B, but it’s where you use empty array entries to handle collisions, e.g. linear probing. Not required for exam.

# Hashing
## Issues with what we've seen so far
So far, we've looked at a few data structures for efficiently searching for the existence of items within the data structure. We looked at Binary Search Trees, then made them balanced using 2-3 Trees.

However, there are some limitations that these structures impose (yes, even 2-3 trees!)

- They require that items be comparable. How do you decide where a new item goes in a BST? You have to answer the question "are you smaller than or bigger than the root"? For some objects, this question may make no sense.
- They give a complexity of $\Theta(\log N)$. Is this good? Absolutely. But maybe we can do better.

## A first attempt: `DataIndexedIntegerSet`

Let us begin by considering the following approach.

For now, we're only going to try to improve issue #2 above (improve complexity from $\Theta(\log N)$ to $\Theta(1)$. We're going to not worry about issue #1 (comparability). In fact, we're going to only consider storing and searching for `int`s.

Here's an idea: let's create an ArrayList of type boolean and size 2 billion. Let everything be `false` by default.

- The `add(int x)` method simply sets the x position in our ArrayList to true. This takes $\Theta(1)$ time.
- The `contains(int x)` method simply returns whether the `x` position in our ArrayList is `true` or `false`. This also takes $\Theta(1)$ time!

What are some potential issues with this approach?

- Extremely wasteful. If we assume that a `boolean` takes 1 byte to store, the above needs 2GB of space per `new DataIndexedIntegerSet()`. Moreover, the user may only insert a handful of items...
- What do we do if someone wants to insert a `String`?
  - Let's look at this next. Of course, we may want to insert other things, like Dogs. That'll come soon!

## Solving the word-insertion problem

### Strategy 1: Use the first letter.

### Strategy 2: Avoiding collisions

**Any** 4 digit number can be written **uniquely** in this form. What that means is given 4 digits, $a, b, c, d$ we can write a $\cdot 10^3 + b \cdot 10^2 + c \cdot 10^1 + d \cdot 10^0$ and that gives us a unique 4 digit number: $abcd$.

Why is $10$? It's because there are 10 unique digits in our decimal system: $0, 1, 2, 3, 4, 5, 6, 7, 8, 9$.

Similarly, there are $26$ unique characters in the english lowercase alphabet. Why not give each one a number: $a=1, b=2, \ldots, z=26$. Now, we can write any unique lowercase string in **base 26**. 

**This representation gives a unique integer to every english word containing lowercase letters, much like using base 10 gives a unique representation to every number. We are guaranteed to not have collisions.**

### Where are we?
Recall, we started with wanting to

- Be better than $\Theta(\log N)$. We've now done this for integers and for single english words.

- Allow for non-comparable items. We haven't touched this yet, although we are getting there. So far, we've only learnt how to add integers and english words, both of which are comparable, *but, have we ever used the fact that they are comparable?* I.e., have we ever tried to compare them (like we did in BSTs)? No. So we're getting there, but we haven't actually inserted anything non-comparable yet.

- We have data structures that insert integers and english words. Let's make a quick visit to inserting arbitrary `String` objects, with spaces and all that. And maybe even insert other languages and emojis!

- Further recall that our approach is still very wasteful of memory. We haven't solved that issue yet!

## Handling Integer Overflow and Hash Codes

### Overflow issues

### The inevitable truth.
From the smallest to the largest possible integers, there are a total of 4,294,967,296 integers in Java. Yet, there are more than that many total objects that could be created in Java, and so collision is inevitable.

**We must handle collisions.**

### A subtle point
Note that our problem is not inherently the fact that overflow *exists*. All we wanted was for a way to convert a `String` to a number. Even if overflow *exists*, we do manage to convert a `String` to a number. The inherent problem is caused by the fact that **overflow causes collisions**, which we don't know how to deal with.

Overflow is often bad in other contexts, for instance, it has some unexpected results if you don't know that overflow happens. But here, overflow's existence doesn't ruin the fact that we wanted to convert a `String` to an `int`. So, we have that going for us.

### Hash Codes
In computer science, taking an object and converting it into some integer is called "computing the hash code of the object". For instance, the hashcode of "melt banana" is 839099497.

We looked at how to compute this hashcode for Strings. For other Objects, there are one of two things we do:

- Every Object in Java has a default `.hashcode()` method, which we can use. Java computes this by figuring out *where the `Object` sits in memory* (every section of the memory in your computer has an address!), and uses that memory's address to do something similar to what we did with Strings. This methods gives a *unique* hashcode for every single Java object.
- Sometimes, we write our own `hashCode` method. For example, given a `Dog`, we may use a combination of its `name`, `age` and `breed` to generate a `hashcode`.

### Properties of HashCodes
Hash codes have three necessary properties, which means a hash code must have these properties in order to be **valid**:

1. It must be an Integer
2. If we run `.hashCode()` on an object twice, it should return the same number
3. Two objects that are considered `.equal()` must have the same hash code.

Not all hash codes are created equal, however. If you want your hash code to be considered a **good** hash code, it should:
- Distribute items evenly

**Note that at this point, we know how to add arbitrary objects to our data structure, not only strings.**

### Pending issues
- Space: we still haven't figured out how to use less space.
- Handling Collisions: we have determined that we need to handle collisions, but we haven't actually handled them yet.

## Handling Collisions
Time to address the elephant in the room. The big idea is to change our array ever so slightly to not contain just items, but instead contain a LinkedList (or any other List) of items. So...

Everything in the array is originally empty. If we get a new item, and its hashcode is $h$:

- If there is nothing at index $h$ at the moment, we'll create a new `LinkedList` for index $h$, place it there, and then add the new item to the newly created `LinkedList`.
- If there is already something at index $h$, then there is already a `LinkedList` there. We simply add our new item to that `LinkedList`. 

Note: Our data structure is not allowed to have any duplicate items / keys. *Therefore, we must first check whether the item we are trying to insert is already in this LinkedList. If it is, we do nothing!* This also means that we will insert to the END of the linked list, since we need to check all of the elements anyways.

### Concrete workflow
- `add` item
  - Get hashcode (i.e., index) of item.
  - If index has no item, create new List, and place item there.
  - If index has a List already, check the List to see if item is already in there. If not, add item to List.
- `contains` item
  - Get hashcode (i.e., index) of item.
  - If index is empty, return false.
  - Otherwise, check all items in the List at that index, and if the item exists, return true.

### Runtime Complexity
**Why is contains $\Theta(Q)$?**

Because we need to look at all the items in the LinkedList at the hashcode (i.e., index).

**Why is add $\Theta(Q)$?**

Can't we just add to the beginning of the `LinkedList`, which takes $\Theta(1)$ time? No! Because **we have to check to make sure the item isn't already in the linked list.**

### You gain some, you lose some.
- Space: Still unsolved.
- Handling collisions: done.
- Runtime complexity? We've lost some. In the worst case, all of our items' hashcode could be the same, and so they all go to the same index. If we have $N$ items, it's possible that they **all** go to the same index, creating a linked list of length $N$, providing a runtime of $\Theta(N)$.

## Solving space

### Why keep an ArrayList of size 4 billion around?

Because we wanted to be able to add every `integer` / word / `String` to our data structure. But now that we allow for collisions *anyway*, we can relax this a bit.

An idea: modulo.

### Where we are?
- Space: Has been solved.
- Handling collisions: Done!
- Runtime complexity? We lost some earlier at $\Theta(Q)$ for `add` and `contains`, and then in the `Solving` space section, we realized that we lost some more because our `LinkedLists` will potentially be larger (so `Q` will be larger.)

## Our Final Data Structure: `HashTable`

What we've created now is called a `HashTable`.

- Inputs are converted by a hash function (`hashcode`) into an integer. Then, they're converted to a valid index using the modulus operator (reduce function). Then, they're added at that index (dealing with collisions using `LinkedLists`).
- contains works in a similar fashion by figuring out the valid index, and looking in the corresponding `LinkedList` for the item.

### Dealing with Runtime
In the worst case, all items get sent to the same index! That is, we have just 1 LinkedList, and it has all 100 items.

There are two ways to try to fix this:
- Dynamically growing our hashtable.
- Improving our Hashcodes

### Dynamically growing the hash table
Suppose we have $M$ buckets (indices) and $N$ items. We say that our **load factor** is $N/M$. (Note that the load factor is equivalent to our **best** case runtime, which items are evenly distributed)

1. We have incentive to keep our load factor low (after all, it is the best runtime we could possible achieve!).
2. We do this by setting a **load factor threshold**. As soon as the load factor becomes bigger than this threshold, we resize.
3. At this point, *assuming items are evenly distributed*, all the lists will be approximately $N/M$ items long, resulting in $\Theta(N/M)$ runtime. Remember that $N/M$ is only allowed to be under a constant **load factor threshold**, and so, $\Theta(N/M) = \Theta(1)$.
4. Note also that resizing takes $\Theta(N)$ time.
5. Of course, we need to revisit our assumption of assuming items are evenly distributed. If items are not evenly distributed, our runtime will be $\Theta(N)$ because there could be a single linked list of size $N$.

A small point: when doing the resize, we don't actually need to check if the items are already present in the `LinkedList` or not (because we know there are no duplicates), so we can just add *each ite*m in $\Theta(1)$ time for sure by adding it to the front of the linked list. (Recall that usually we have to search the `LinkedList` to make sure the item isn't there... but we can skip that step when resizing.)

### Evenly distributed?
Items will distribute evenly if we have good hash codes (i.e. hashcodes which give fairly random values for different items.) Doing this in general is.. well... hard.

Some general good rules of thumb:

- Use a 'base' strategy similar to the one we developed earlier.
- Use a 'base' that's a small prime.
  - Base 126 isn't actually very good, because using base 126 means that any string that ends in the same last 32 characters has the same hashcode.
  - This happens because of overflow.
  - Using prime numbers helps avoid overflow issues (i.e., collisions due to overflow).
  - Why a small prime? Because it's easier to compute.